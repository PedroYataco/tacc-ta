{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2b6a7733a884b02a19fdb91d88fc6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eee0b24f3db45a58cde24fa56fbe077",
              "IPY_MODEL_36701c2aa9b842a1afe2a54cde6b656e",
              "IPY_MODEL_400d913def0549edaaa5e4510be46a14"
            ],
            "layout": "IPY_MODEL_7a57d82c49674f1aa4fed2450e4afe89"
          }
        },
        "0eee0b24f3db45a58cde24fa56fbe077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b32d69d1042446f8c21bfb49edb5616",
            "placeholder": "​",
            "style": "IPY_MODEL_cb01ce8e2f4b4bc1ba3beeae92597f97",
            "value": "Map: 100%"
          }
        },
        "36701c2aa9b842a1afe2a54cde6b656e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7e9dce21e64603a4186ea8965ba25d",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_040a17f5d5434b639900d2eaf72c48de",
            "value": 148
          }
        },
        "400d913def0549edaaa5e4510be46a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d302b1677849bfa04b266dc40afb2e",
            "placeholder": "​",
            "style": "IPY_MODEL_5cb234bf00134b819519726a9056cfa6",
            "value": " 148/148 [00:00&lt;00:00, 604.79 examples/s]"
          }
        },
        "7a57d82c49674f1aa4fed2450e4afe89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b32d69d1042446f8c21bfb49edb5616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb01ce8e2f4b4bc1ba3beeae92597f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e7e9dce21e64603a4186ea8965ba25d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040a17f5d5434b639900d2eaf72c48de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7d302b1677849bfa04b266dc40afb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb234bf00134b819519726a9056cfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Htj65rZ-QqXR"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "id": "QA8ah92TvAiK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "x4krcfakN4Kh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_path = 'corpus.csv'\n",
        "df = pd.read_csv(corpus_path, encoding='utf-8')\n",
        "df['text'] = df['Title'] + '. ' + df['Body']"
      ],
      "metadata": {
        "id": "UyeclVmnNprW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train(files=[corpus_path], vocab_size=52000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "tokenizer.save_model(\".\", \"shipibo_tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGqNtMyTO3Sq",
        "outputId": "d53808a0-2a1b-4096-ae6b-be58f469b2a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./shipibo_tokenizer-vocab.json', './shipibo_tokenizer-merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Cargar el tokenizador desde los archivos vocab y merges\n",
        "tokenizer = GPT2TokenizerFast(\n",
        "    vocab_file=\"shipibo_tokenizer-vocab.json\",\n",
        "    merges_file=\"shipibo_tokenizer-merges.txt\"\n",
        ")\n",
        "\n",
        "# Añadir tokens especiales\n",
        "tokenizer.add_special_tokens({\n",
        "    \"pad_token\": \"<pad>\",\n",
        "    \"unk_token\": \"<unk>\",\n",
        "    \"mask_token\": \"<mask>\",\n",
        "    \"bos_token\": \"<s>\",\n",
        "    \"eos_token\": \"</s>\",\n",
        "})\n",
        "\n",
        "# Verificar si se han añadido correctamente los tokens especiales\n",
        "print(\"Tokens especiales añadidos:\", tokenizer.special_tokens_map)"
      ],
      "metadata": {
        "id": "8CjitNFHO805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe44d1f-5b1e-4dfb-dc02-72010ddeba80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens especiales añadidos: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de texto en Shipibo-Konibo\n",
        "input_text = \"Huestíora joni ronqui\"\n",
        "tokens = tokenizer.encode(input_text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Des-tokenización\n",
        "decoded_text = tokenizer.decode(tokens)\n",
        "print(\"Texto decodificado:\", decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b0C5LCcgi8V",
        "outputId": "96d49806-4454-4ae3-bcba-513365709e2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: [44, 89, 992, 88, 132, 260, 363, 321, 795, 85, 89, 77]\n",
            "Texto decodificado: Huestíora joni ronqui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset\n",
        "\n",
        "# Crear el modelo desde cero\n",
        "config = GPT2Config(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    n_positions=1024,\n",
        "    n_ctx=1024,\n",
        "    n_embd=768,\n",
        "    n_layer=12,\n",
        "    n_head=12,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "model = GPT2LMHeadModel(config)\n",
        "\n",
        "# Crear el dataset de Hugging Face\n",
        "corpus_path = 'corpus.csv'\n",
        "df = pd.read_csv(corpus_path)\n",
        "df['text'] = df['Title'] + ' ' + df['Body']\n",
        "dataset = Dataset.from_pandas(df[['text']])\n",
        "\n",
        "# Tokenizar el corpus\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Crear el data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Configurar los argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "# Inicializar el Trainer y entrenar el modelo\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "f2b6a7733a884b02a19fdb91d88fc6f6",
            "0eee0b24f3db45a58cde24fa56fbe077",
            "36701c2aa9b842a1afe2a54cde6b656e",
            "400d913def0549edaaa5e4510be46a14",
            "7a57d82c49674f1aa4fed2450e4afe89",
            "2b32d69d1042446f8c21bfb49edb5616",
            "cb01ce8e2f4b4bc1ba3beeae92597f97",
            "5e7e9dce21e64603a4186ea8965ba25d",
            "040a17f5d5434b639900d2eaf72c48de",
            "b7d302b1677849bfa04b266dc40afb2e",
            "5cb234bf00134b819519726a9056cfa6"
          ]
        },
        "id": "gPQpbPJehB0i",
        "outputId": "927557e7-c9e1-4315-ea30-6e02bc1e0106"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/148 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2b6a7733a884b02a19fdb91d88fc6f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='370' max='370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [370/370 02:41, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=370, training_loss=5.987418179898649, metrics={'train_runtime': 163.4094, 'train_samples_per_second': 9.057, 'train_steps_per_second': 2.264, 'total_flos': 386712207360000.0, 'train_loss': 5.987418179898649, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo y el tokenizador\n",
        "trainer.save_model(\"./results\")  # Esto guarda el modelo, la configuración y el tokenizador\n",
        "tokenizer.save_pretrained(\"./results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtuMvmdjmhCd",
        "outputId": "d34caf50-4ead-4336-cc8d-339520b95615"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./results/tokenizer_config.json',\n",
              " './results/special_tokens_map.json',\n",
              " './results/vocab.json',\n",
              " './results/merges.txt',\n",
              " './results/added_tokens.json',\n",
              " './results/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo entrenado\n",
        "model = GPT2LMHeadModel.from_pretrained('./results')\n"
      ],
      "metadata": {
        "id": "LuhKHDgZlZxi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def capitalize_sentences(text):\n",
        "    sentences = re.split('(?<=[.!?]) +', text)  # Dividir el texto en oraciones\n",
        "    capitalized_sentences = [sentence.capitalize() for sentence in sentences]\n",
        "    return ' '.join(capitalized_sentences)\n",
        "\n",
        "# Función para generar texto\n",
        "\n",
        "def generate_story(prompt, max_length=512, num_return_sequences=1):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    outputs = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,  # Para generar texto de manera más creativa\n",
        "        top_k=50,  # Para limitar el número de palabras a considerar para cada paso\n",
        "        top_p=0.95  # Para la estrategia de muestreo de núcleo (nucleus sampling)\n",
        "    )\n",
        "\n",
        "    stories = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    capitalized_stories = [capitalize_sentences(story) for story in stories]\n",
        "    return capitalized_stories\n",
        "\n",
        "\n",
        "# Ejemplo de uso\n",
        "prompt = \"moatian ronki ipaonike\"\n",
        "generated_stories = generate_story(prompt, max_length=300, num_return_sequences=3)\n",
        "\n",
        "\n",
        "for i, story in enumerate(generated_stories):\n",
        "    print(f\"Cuento {i + 1}:\\n{story}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRjMLmxemn7W",
        "outputId": "f544d9b4-474e-4692-b2e4-b8640e679932"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuento 1:\n",
            "Moatian ronki ipaonike ronki ipaonike icha riki, jawen jonibaonbo. Jatianki akin. Ja ainbo ika iki; jato baritia iki, jaweki ati iki. Caxon, ja joni ronki ipaonike. Jatian ronki aka iki, ja xeati yoikin riki, ja ainbora, ja ainbo ronki ipaonike, ani kaa iki. Natoya, jainxon, ja, ja jatian jakasi. Nato ja bakeai, jawen ibo yoia iki. Ja jawen rayos. Jatian wetsa nete'ronki ipaonike nato kikin soiki ika iki, ja ani, ja jonin ronki aka iki. Jatian ja ronki ikai, jawen akin. Ja bake, jakiribiki nato ainbo ronki aka iki, jawen awin eata. Jatian ja bake, jawen awin. Earaax, jawen awin betan jawen bake ika iki. Ja yakata iki. Ja jonin icha jain ikenbi, ika iki. Ja jonin westiora joni ronki ipaonike, ja nonti ronki ika iki, jawen jawen ibon benai. Jatian jaton piti aka iki, jawen rayoski, moa ja inka jawen bene ipaonike jawen rayosbi. Ja bake. Ja xeati jatian jawen rayos. Ja kaa iki. Jatian ja joninki yoia iki. Jainxon, ja bake. Ja ainbaon moa moa moa ikai jawen rayos. Jatian jawen awinra mia jawen rayos moa nete jawen bake. Jatian ja inka. Ja bake ronki aka iki. Moa, ja ainbaon ronki yoashiko inka, jawenya. Moa jato aka iki. Ja inka ronki ika iki. Jatian ronki aka iki, ja yoashiko yoia iki, jawen mapo joni jawen awinti, jawen awinribi moa joni ika iki\n",
            "\n",
            "Cuento 2:\n",
            "Moatian ronki ipaonikexon ini ronki ipaonike, jaronki inkanbo ronki riki ronki ipaonike. Ja onan. Moa onan ronki ipaonike, jawen papan ronki aka iki. Ja ronki ika iki. Nato isa ronki aka iki. Moa ikai jato aka iki, jawen bakebo jawen rayos ronki aka iki. Ja ainbaon, jawen bakebo, ja ronki ika iki. Jatian jato aka iki, iki, ja yoashiko kaa iki, jawen awin ronki ronki, jawen rayos, ja jonibo iki; ja joni ronki aka iki, jato, jawen rayos. Jatian ino betan jawen awin ronki aka iki, ja bimi min aka iki, ja wai wai, jawen kexa. Ja bakeranon, jawen westiora jonin ronki ipaonike, jawen rayos ronki ika iki. Ja xeati. Jatian ronki ika iki. Jatian ronki ika iki, ja inkanma iki. Jato aka iki. Ja bake ronki aka iki. Jatian ronki, jawen rayos moabi; jawen awin, ja bekana iki. Caxon; jaskaaxon ronki ika iki. Jainxon minki, jawen awin ronki aka iki, jawen rayos ronki ja; moa. Jatian jawenribi ronki ika iki. Moa. Jatian jawen rayos ronki aka iki, jawen rayos ika iki ea iki; moa. Jatian ronki aka iki. Jatian jawen awinki ika iki, jainxon jawen bake yoyo iki, moa kaa iki. Jatianki ika iki. Jatian moa jawen ibo aka iki. Natoki, ja bake kaa iki. Jatian jawen rayos. Ja joni kaa iki, jawen pia iki. Jatian ronki ika iki, jato aka iki. Jatian jato aka iki, ja\n",
            "\n",
            "Cuento 3:\n",
            "Moatian ronki ipaonike betan ini ini wetsa ronki ipaonike, non betan onan ronki ikai,; jatibi jatibi jaweki ronki ipaonike, jawen awin, jawen awin, jawen ibo aka iki, inonta iki, itan jawen rekenxon. Ja inka ronki ipaonike, jawen awinti, jawen jato aka iki moa jawen awin, ja kaa iki. Moa ani iki. Jatian ja inkan jakon, ja bakebo jawen awin, ja bakeai. Jainoax jawen tita ronki ika iki. Westiora jonin jawen nonti iki, jonin ronki ika iki. Jatian ronki jawen bake ainbo ronki ipaonike moa yoia iki. Ja moa jawen. Ja bakera ikaima iki. Nato kikinti, jawen awin ea axon jawen bene riki, jawen awin ja bake ika iki. Jatian jawen awin, jawenkanai, ja bakeke; jawen rayoskana iki, jawen jatian jato moa westiora jawen nontibo. Ja oina iki, jawen rayos. Jawen xobon moa aka iki. Ikaxbi; kaa iki, ja bake, jawen rayos kai. Jatian jatibi jawen awin kaa iki, ja bake; ja inka akin aka iki. Ja baken joni ronki jaton bakebo, jainxon jawen awin, jawen rayos kaa iki. Jatian jawen nontiti iki. Jaskara kopi. Jaskaa shinanki, jawen rayos kaa iki, jawen bene jatian jawen papabi iki, ja bakea iki, ja yoashiko inka, jawen rayos moa kaa iki, jawen rayos. Ja ainbaon kaa iki, jawen awin ronki aka iki. Minronki aka iki, jawen rayos. Jatian onanyama joni kaa iki, jawen bene, jawen bake, jawen,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metricas para evaluar el cuento generado"
      ],
      "metadata": {
        "id": "9dhfpk4FqSkd"
      }
    }
  ]
}